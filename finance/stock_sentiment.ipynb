{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMbIxD/KJ1DVwcLYqG95jQy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JianfengMI/MLprojects/blob/main/finance/stock_sentiment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Try to use Sentiment analysis to predict stock price\n",
        "- retrieve stock price\n",
        "- sentiment analysis - retrieve text and converting it into a numeric value to represent the feeling of the text"
      ],
      "metadata": {
        "id": "_uNRYClxyuoz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## install / import packages"
      ],
      "metadata": {
        "id": "bI1Q3rKGzc88"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1szdqrV_yoDp"
      },
      "outputs": [],
      "source": [
        "! pip install yfinance"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from textblob import TextBlob\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.graph_objects as go"
      ],
      "metadata": {
        "id": "jGBY1O0nzng0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Example pulling microsoft stock\n",
        "msft = yf.Ticker(\"MSFT\")"
      ],
      "metadata": {
        "id": "7IGutai8z7rU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hist = msft.history(period=\"max\")"
      ],
      "metadata": {
        "id": "4s_2hZ7l0GzD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hist.head()"
      ],
      "metadata": {
        "id": "X6CGR2QJ0Zrk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hist.Open.plot(figsize=(12,4), title=\"Microsoft Stock Price\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "24jrleZo0LXy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pull more stocks (3 years of history)\n",
        "stocks = [\n",
        "    \"^GSPC\",\n",
        "    \"ETSY\",\n",
        "    \"PINS\",\n",
        "    \"TSLA\",\n",
        "    \"SHOP\",\n",
        "    \"O\",\n",
        "    \"MELI\",\n",
        "    \"ISRG\",\n",
        "    \"DIS\",\n",
        "    \"BRK-B\",\n",
        "    \"AMZN\",\n",
        "    \"ZM\",\n",
        "    \"PFE\",\n",
        "    \"CLX\",\n",
        "    \"DPZ\",\n",
        "    \"RTX\",\n",
        "]"
      ],
      "metadata": {
        "id": "VS-IcbP108PE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hists = {}\n",
        "for stock in stocks:\n",
        "    hists[stock] = yf.Ticker(stock).history(period=\"3y\")"
      ],
      "metadata": {
        "id": "J981_ZE81PlT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plot the stock price with plotly\n",
        "for stock in stocks:\n",
        "  temp_df = hists[stock].copy()\n",
        "\n",
        "  fig = go.Figure(\n",
        "      data=[go.Candlestick(\n",
        "          x=temp_df.index,\n",
        "          open=temp_df[\"Open\"],\n",
        "          high=temp_df[\"High\"],\n",
        "          low=temp_df[\"Low\"],\n",
        "          close=temp_df[\"Close\"]\n",
        "      )]\n",
        "  )\n",
        "  fig.update_layout(title=stock, xaxis_rangeslider_visible=False)\n",
        "  fig.show()"
      ],
      "metadata": {
        "id": "zGGaLUa31z_e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## pull Tweets about each stock"
      ],
      "metadata": {
        "id": "ze5Ox-wY29Op"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# try CLX fisrt\n",
        "hists[\"CLX\"].index.min()"
      ],
      "metadata": {
        "id": "n6ZaSzQ_28dx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stock = \"CLX\""
      ],
      "metadata": {
        "id": "ekZElM7k_3ao"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "562cc28e"
      },
      "source": [
        "! pip install snscrape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import libraries\n",
        "import tweepy\n",
        "import os\n",
        "import pandas as pd\n",
        "from tqdm.notebook import tqdm\n",
        "import snscrape.modules.twitter as sntwitter\n",
        "\n",
        "# scrape data from tweeter\n",
        "tweets_list = []\n",
        "\n",
        "for i, tweet in tqdm(\n",
        "    enumerate(\n",
        "        sntwitter.TwitterSearchScraper(\n",
        "            f\"${stock} since:2022-06-27 until:2025-06-24\"\n",
        "        ).get_items()),\n",
        "    total=1000):\n",
        "    if i > 1000:\n",
        "      break\n",
        "    tweets_list.append([tweet.date, tweet.id, tweet.content, tweet.user.username])\n",
        "\n",
        "\n",
        "tweets_df = pd.DataFrame(tweets_list, columns=[\"date\", \"id\", \"content\", \"username\"])"
      ],
      "metadata": {
        "id": "_L6xO_Ed_9KH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## since snscrape doesn't work anymore, try using 'tweepy' library. Note that youâ€™ll need X API credentials (API Key, API Secret, Access Token, and Access Token Secret) to use this script."
      ],
      "metadata": {
        "id": "gFiikKluEQCA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tweepy\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "import os\n",
        "\n",
        "# Replace these with your own X API credentials\n",
        "API_KEY = \"7xcxm004fsnWToVBd4ej5D5cz\"\n",
        "API_SECRET = \"wh1wLvROvzQ9iGw0TGbutiaBIiNH09jLsrhkGJGc1tRc5JB1j3\"\n",
        "ACCESS_TOKEN = \"254562826-9YQT8qvsQdSn8Bb4OXZhN17Rymg06gvb7qtg2DGW\"\n",
        "ACCESS_TOKEN_SECRET = \"XEDutvVqTxWnzJeWiIIRBf2r444MpqlHzsEUJVqrjFHHn\"\n",
        "\n",
        "# Authenticate with X API\n",
        "auth = tweepy.OAuthHandler(API_KEY, API_SECRET)\n",
        "auth.set_access_token(ACCESS_TOKEN, ACCESS_TOKEN_SECRET)\n",
        "api = tweepy.API(auth, wait_on_rate_limit=True)\n",
        "\n",
        "# Define the search query and date range\n",
        "search_query = \"$CLX -filter:retweets\"  # Search for $CLX, exclude retweets\n",
        "since_date = \"2022-06-25\"\n",
        "until_date = \"2025-06-25\"  # Current date as of request\n",
        "\n",
        "# Function to convert date to X API format (YYYYMMDDHHMM)\n",
        "def format_date_for_api(date_str):\n",
        "    date_obj = datetime.strptime(date_str, \"%Y-%m-%d\")\n",
        "    return date_obj.strftime(\"%Y%m%d%H%M\")\n",
        "\n",
        "# Initialize a list to store tweet data\n",
        "tweets_data = []\n",
        "\n",
        "# Search for tweets\n",
        "try:\n",
        "    for tweet in tweepy.Cursor(api.search_tweets,\n",
        "                             q=search_query,\n",
        "                             since_id=None,\n",
        "                             until=format_date_for_api(until_date),\n",
        "                             lang=\"en\").items(1000):  # Limit to 1000 tweets for this example\n",
        "        tweet_date = tweet.created_at\n",
        "        if tweet_date >= datetime.strptime(since_date, \"%Y-%m-%d\"):\n",
        "            tweets_data.append({\n",
        "                \"created_at\": tweet.created_at,\n",
        "                \"username\": tweet.user.screen_name,\n",
        "                \"text\": tweet.text,\n",
        "                \"retweet_count\": tweet.retweet_count,\n",
        "                \"favorite_count\": tweet.favorite_count\n",
        "            })\n",
        "\n",
        "    # Create a DataFrame\n",
        "    df = pd.DataFrame(tweets_data)\n",
        "\n",
        "    # Save to CSV\n",
        "    output_file = \"clx_threads_2022_06_25_to_2025_06_25.csv\"\n",
        "    df.to_csv(output_file, index=False)\n",
        "    print(f\"Data saved to {output_file}\")\n",
        "\n",
        "except tweepy.TweepyException as e:\n",
        "    print(f\"Error occurred: {e}\")"
      ],
      "metadata": {
        "id": "zujK_jMbEjCo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# it looks X free account doens't have access to retrieving posts. Have to change to other approaches\n",
        "-let's try using yahoo finance headlines"
      ],
      "metadata": {
        "id": "EMafKOZaMFQq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# install necessary packages\n",
        "!pip install transformers feedparser requests"
      ],
      "metadata": {
        "id": "PLc7d5nSMao3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import feedparser\n",
        "import requests\n",
        "from transformers import pipeline"
      ],
      "metadata": {
        "id": "7VqDP475M0FX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# use <finbert> model\n",
        "pipe = pipeline(\"text-classification\", model=\"ProsusAI/finbert\")"
      ],
      "metadata": {
        "id": "PFKxeDZ3M16l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(pipe(\"stocks rallied and the british pound gained.\"))"
      ],
      "metadata": {
        "id": "cv2Fe1vFNLFS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ticker = \"META\"\n",
        "keyword = 'meta'\n",
        "\n",
        "rss_url = f\"https://finance.yahoo.com/rss/headline?s={ticker}\"\n",
        "feed = feedparser.parse(rss_url)\n",
        "\n",
        "total_score = 0\n",
        "num_articles = 0\n",
        "\n",
        "for i, entry in enumerate(feed.entries):\n",
        "    if keyword.lower() not in entry.title.lower():\n",
        "        continue\n",
        "    else:\n",
        "        print(f'Title: {entry.title}')\n",
        "        print(f'Link: {entry.link}')\n",
        "        print(f'Published: {entry.published}')\n",
        "        print(f'Summary: {entry.summary}')\n",
        "\n",
        "        sentiment = pipe(entry.summary)[0]\n",
        "\n",
        "        print(f'Sentiment: {sentiment[\"label\"]}, Score: {sentiment[\"score\"]}')\n",
        "        print('-' * 50)\n",
        "\n",
        "        if sentiment['label'] == 'positive':\n",
        "            total_score += sentiment['score']\n",
        "            num_articles += 1\n",
        "        elif sentiment['label'] == 'negative':\n",
        "            total_score -= sentiment['score']\n",
        "            num_articles += 1\n",
        "final_score = total_score / num_articles if num_articles > 0 else 0\n",
        "print(f'Overall sentiment:{\"Positive\" if final_score >= 0.15 else \"Negative\" if final_score <=-0.15 else \"Neutral\"} {final_score}')"
      ],
      "metadata": {
        "id": "lckGu4DtNZXZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "keyword = 'tesla'\n",
        "date = '2025-06-24' # free version only allow to access ONE month old\n",
        "API_KEY = '71e85c59c5ec44a798757332a7a20ca2'\n",
        "\n",
        "url = (\n",
        "    'https://newsapi.org/v2/everything?'\n",
        "    f'q={keyword}&'\n",
        "    f'from={date}&'\n",
        "    'sortBy=popularity&'\n",
        "    f'apiKey={API_KEY}'\n",
        ")\n",
        "response = requests.get(url)\n",
        "articles = response.json()[\"articles\"]\n",
        "articles = [article for article in articles if keyword.lower() in article[\"title\"].lower() or keyword.lower() in article[\"description\"].lower()]\n",
        "\n",
        "total_score = 0\n",
        "num_articles = 0\n",
        "\n",
        "for i, article in enumerate(articles):\n",
        "        print(f'Title: {article[\"title\"]}')\n",
        "        print(f'Link: {article[\"url\"]}')\n",
        "        print(f'Description: {article[\"description\"]}')\n",
        "\n",
        "        sentiment = pipe(article['content'])[0]\n",
        "\n",
        "        print(f'Sentiment: {sentiment[\"label\"]}, Score: {sentiment[\"score\"]}')\n",
        "        print('-' * 50)\n",
        "\n",
        "        if sentiment['label'] == 'positive':\n",
        "            total_score += sentiment['score']\n",
        "            num_articles += 1\n",
        "        elif sentiment['label'] == 'negative':\n",
        "            total_score -= sentiment['score']\n",
        "            num_articles += 1\n",
        "final_score = total_score / num_articles if num_articles > 0 else 0\n",
        "print(f'Overall sentiment:{\"Positive\" if final_score >= 0.15 else \"Negative\" if final_score <=-0.15 else \"Neutral\"} {final_score}')"
      ],
      "metadata": {
        "id": "-S4vZzrrSywH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}